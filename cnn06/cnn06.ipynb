{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EaJhjclU_MO"
   },
   "source": [
    "# Neural Style Transfer with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DVLn-P7ZV7Mp"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Vm4g6iSU_MQ"
   },
   "source": [
    "---\n",
    "## Introduction\n",
    "\n",
    "General process \n",
    "1. Set up a network that computes layer-activations for the style-reference image, the target image, and the generated image at the same time. \n",
    "2. Use these layer activations to define the loss function.\n",
    "3. Set up a gradient-ascnt process to minimize this loss function by modifying the generated image. \n",
    "\n",
    "### Defining Initial Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0cY0N4f1U_MS"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Image Paths \n",
    "target_image_path = '/content/drive/My Drive/Colab Notebooks/inputs/IU_portrait.png'\n",
    "style_reference_image_path = '/content/drive/My Drive/Colab Notebooks/style/the-starry-night.jpg'\n",
    "\n",
    "# Dimensins for the generated picture\n",
    "width, height = load_img(target_image_path).size\n",
    "img_height = 400\n",
    "img_width = int(width * img_height / height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UuI0xobsU_MX"
   },
   "source": [
    "### Auxiliary Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KwhqhcofU_MZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import vgg19 \n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_height, img_width))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img \n",
    "\n",
    "def deprocess_image(image):\n",
    "    # Reverses a transformation in vgg19.preprocess_input()\n",
    "    image[:, :, 0] += 103.939\n",
    "    image[:, :, 1] += 116.779\n",
    "    image[:, :, 2] += 123.68 \n",
    "    # Convert from BGR to RGB (also vgg19.preprocess_input())\n",
    "    image = image[:, :, ::-1]\n",
    "    return np.clip(image, 0, 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBMln7I0U_Mf"
   },
   "source": [
    "### Loading VGG19 and Applying to Three Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zP6XvNSSU_Mg"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "\n",
    "# Generated image is a placeholder others are constant \n",
    "target_image = K.constant(preprocess_image(target_image_path))\n",
    "style_image = K.constant(preprocess_image(style_reference_image_path))\n",
    "generated_image = K.placeholder((1, img_height, img_width, 3))\n",
    "\n",
    "# Combine the images into a \"batch\" \n",
    "input_tensor = K.concatenate([target_image, style_image, generated_image], axis=0)\n",
    "\n",
    "# Load the model \n",
    "model = vgg19.VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9wh29YzsU_Ml"
   },
   "source": [
    "### Defining the Loss Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "v6mf_jFVU_Mn"
   },
   "outputs": [],
   "source": [
    "def content_loss(target, generated):\n",
    "    return K.sum(K.square(generated - target))\n",
    "\n",
    "def gram_matrix(x):\n",
    "    \"\"\"Captures the 'style' of an image.\"\"\"\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram \n",
    "\n",
    "def style_loss(style, generated):\n",
    "    S = gram_matrix(style)\n",
    "    G = gram_matrix(generated)\n",
    "    channels = 3 \n",
    "    size = img_height * img_width\n",
    "    return K.sum(K.square(S - G)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    a = K.square(x[:, :img_height - 1, :img_width - 1, :] -\n",
    "                 x[:, 1:, :img_width - 1, :])\n",
    "    b = K.square(x[:, :img_height - 1, :img_width - 1, :] -\n",
    "                 x[:, :img_height - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZu6FPaYU_Ms"
   },
   "source": [
    "### Defining the Final Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NRDHQI8UU_Mu"
   },
   "outputs": [],
   "source": [
    "layers_dict = {layer.name: layer.output for layer in model.layers}\n",
    "content_layer = 'block5_conv2'\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "                'block5_conv1']\n",
    "\n",
    "# Weights in the weighted average \n",
    "total_variation_weight = 1e-2 \n",
    "style_weight = 0.5 \n",
    "content_weight = 0.5\n",
    "\n",
    "# Overall Loss \n",
    "loss = K.variable(0.)\n",
    "\n",
    "# Loss += Content Loss \n",
    "layer_features = layers_dict[content_layer]\n",
    "target_image_featues = layer_features[0, :, :, :]\n",
    "generated_image_features = layer_features[2, :, :, :]\n",
    "loss = loss + content_weight * content_loss(target_image_featues,\n",
    "                                            generated_image_features)\n",
    "\n",
    "# Loss += Style Loss \n",
    "for layer_name in style_layers: \n",
    "    layer_features = layers_dict[layer_name]\n",
    "    style_image_features = layer_features[1, :, :, :]\n",
    "    generated_image_features = layer_features[2, :, :, :]\n",
    "    temp_style_loss = style_loss(style_image_features, \n",
    "                                 generated_image_features)\n",
    "    loss = loss + (style_weight / len(style_layers)) * temp_style_loss\n",
    "    \n",
    "# Loss += Variation Loss \n",
    "loss = loss + total_variation_weight * total_variation_loss(generated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZ72pTSxU_Mz"
   },
   "source": [
    "### Setting up Gradient-Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HrVX8Wa1U_M0"
   },
   "outputs": [],
   "source": [
    "grads = K.gradients(loss, generated_image)[0]\n",
    "fetch_loss_and_grads = K.function([generated_image], [loss, grads])\n",
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        x = x.reshape((1, img_height, img_width, 3))\n",
    "        outs = fetch_loss_and_grads([x])\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f5tigqZzU_M6"
   },
   "source": [
    "### Style Transfer Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 259799,
     "status": "ok",
     "timestamp": 1544960409291,
     "user": {
      "displayName": "JT Bergman",
      "photoUrl": "https://lh6.googleusercontent.com/-f2QnRTfJH_M/AAAAAAAAAAI/AAAAAAAAAfo/ObyOWArlkVQ/s64/photo.jpg",
      "userId": "17974959315589527400"
     },
     "user_tz": -540
    },
    "id": "cHMORPzVU_M8",
    "outputId": "2087e77b-6ca6-4747-8d1f-f5ba3491d88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 1\n",
      "Current loss value: 1192790300.0\n",
      "Start of iteration 2\n",
      "Current loss value: 576547700.0\n",
      "Start of iteration 3\n",
      "Current loss value: 413295300.0\n",
      "Start of iteration 4\n",
      "Current loss value: 337355140.0\n",
      "Start of iteration 5\n",
      "Current loss value: 294651900.0\n",
      "Start of iteration 6\n",
      "Current loss value: 264794980.0\n",
      "Start of iteration 7\n",
      "Current loss value: 238312660.0\n",
      "Start of iteration 8\n",
      "Current loss value: 222517490.0\n",
      "Start of iteration 9\n",
      "Current loss value: 208912460.0\n",
      "Start of iteration 10\n",
      "Current loss value: 193770380.0\n",
      "Start of iteration 11\n",
      "Current loss value: 184535520.0\n",
      "Start of iteration 12\n",
      "Current loss value: 178183970.0\n",
      "Start of iteration 13\n",
      "Current loss value: 171971380.0\n",
      "Start of iteration 14\n",
      "Current loss value: 166173570.0\n",
      "Start of iteration 15\n",
      "Current loss value: 162028960.0\n",
      "Start of iteration 16\n",
      "Current loss value: 158924140.0\n",
      "Start of iteration 17\n",
      "Current loss value: 155823730.0\n",
      "Start of iteration 18\n",
      "Current loss value: 153069360.0\n",
      "Start of iteration 19\n",
      "Current loss value: 150175220.0\n",
      "Start of iteration 20\n",
      "Current loss value: 147637300.0\n",
      "Start of iteration 21\n",
      "Current loss value: 145015890.0\n",
      "Start of iteration 22\n",
      "Current loss value: 142706100.0\n",
      "Start of iteration 23\n",
      "Current loss value: 140533580.0\n",
      "Start of iteration 24\n",
      "Current loss value: 138491380.0\n",
      "Start of iteration 25\n",
      "Current loss value: 136699800.0\n",
      "Start of iteration 26\n",
      "Current loss value: 135008320.0\n",
      "Start of iteration 27\n",
      "Current loss value: 133602060.0\n",
      "Start of iteration 28\n",
      "Current loss value: 132335416.0\n",
      "Start of iteration 29\n",
      "Current loss value: 130920300.0\n",
      "Start of iteration 30\n",
      "Current loss value: 129522990.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import imageio\n",
    "\n",
    "base_path = '/content/drive/My Drive/Colab Notebooks/outputs/'\n",
    "result_prefix = 'result'\n",
    "iterations = 30\n",
    "\n",
    "x = preprocess_image(target_image_path)\n",
    "x = x.flatten()\n",
    "for i in range(1, iterations + 1):\n",
    "    print('Start of iteration', i)\n",
    "    x, min_val, _ = fmin_l_bfgs_b(evaluator.loss, x, fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    img = x.copy().reshape((img_height, img_width, 3))\n",
    "    img = deprocess_image(img)\n",
    "    fname = base_path + str(i) + '.png'\n",
    "    imageio.imwrite(fname, img)\n",
    "\n",
    "final_path = base_path + 'final.png'\n",
    "imageio.imwrite(final_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Creating GIFs from Outputs \n",
    "Before showing you some of my results, here is a helper function you can use to transform a directory of numerically ordered photos (1.png, 2.png, 3.jpg, etc.) into a GIF. This allows us to see the photo transforming over time, which is pretty cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "n6H1icTKU_NF"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import re \n",
    "import imageio\n",
    "\n",
    "# only keep files that followed the `number.png` convention\n",
    "file_format = re.compile(r'(\\d+).png')\n",
    "\n",
    "# Sort the images numerically (e.g. 1.png, 2.png, ...)\n",
    "def sort_key(filename):\n",
    "    \"\"\"Return the numeric portion of filename.\"\"\"\n",
    "    return int(filename.split('.')[0])\n",
    "\n",
    "# Transform the files in the directory into a gif \n",
    "def images_to_gif(source_dir, name='final.gif'):\n",
    "    \"\"\"Turn a directory of numerically labeled photos into gifs.\"\"\"\n",
    "    files = sorted([fname for fname in os.listdir(source_dir) \n",
    "                    if file_format.match(fname)], key=sort_key)\n",
    "    images = [imageio.imread(os.path.join(source_dir, fname)) \n",
    "              for fname in files]\n",
    "    imageio.mimsave(os.path.join(source_dir, name), images, \n",
    "                    'GIF', duration=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used this to generate an image for all of my photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = '/Users/jtbergman/GitHub/deep-learning-code/cnn06/outputs/img5/'\n",
    "images_to_gif(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results\n",
    "_Note: Links to all of the files are provided at the end of the notebook._\n",
    "\n",
    "### Example 1\n",
    "```python \n",
    "# Images\n",
    "content_image = './inputs/germany.jpg'\n",
    "style_image = './style/the_shipwreck_of_the_minotaur.jpg'\n",
    "\n",
    "# Parameters\n",
    "total_variation_weight = 1e-4\n",
    "style_weight = 1.\n",
    "content_weight = 0.025\n",
    "```\n",
    "\n",
    "![Neckarfront in Tübingeng, Germany](./outputs/img1/final.gif)\n",
    "\n",
    "### Example 2\n",
    "```python \n",
    "# Images\n",
    "content_image = './inputs/IU_portrait.png'\n",
    "style_image = './style/femme_nue_assise_pablo_picasso.jpg'\n",
    "\n",
    "# Parameters\n",
    "total_variation_weight = 1e-4\n",
    "style_weight = 1.\n",
    "content_weight = 0.025\n",
    "```\n",
    "\n",
    "![IU + Femme Nue Assise](./outputs/img2/final.gif)\n",
    "\n",
    "### Example 3\n",
    "```python \n",
    "# Images\n",
    "content_image = './inputs/IU_portrait.png'\n",
    "style_image = './style/composition_vii.jpg'\n",
    "\n",
    "# Parameters\n",
    "total_variation_weight = 1e-2\n",
    "style_weight = 0.5\n",
    "content_weight = 0.5\n",
    "```\n",
    "\n",
    "![IU + composition vii](./outputs/img3/final.gif)\n",
    "\n",
    "### Example 4\n",
    "```python \n",
    "# Images\n",
    "content_image = './inputs/IU_portrait.png'\n",
    "style_image = './style/the-starry-night.jpg'\n",
    "\n",
    "# Parameters\n",
    "total_variation_weight = 1e-2\n",
    "style_weight = 0.5\n",
    "content_weight = 0.5\n",
    "```\n",
    "\n",
    "![IU + Starry Night](./outputs/img4/final.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary \n",
    "In my opinion, this is a lot cooler than DeepDream because we have way more influence over what the final image look likes. I actually think it would be better to actual slow the learning down so that we can create GIFs with much smoother transitions. If you look a the outputs,by just the third iteration the generated image is usually a lot closer to the final output than the content image. \n",
    "\n",
    "### Original Neural Style Transfer Paper\n",
    "You can find the original neural style transfer paper [here](https://arxiv.org/pdf/1508.06576.pdf)\n",
    "\n",
    "### Content Images \n",
    "The first content image is of the Neckarfront in Tübingen, Germany. If you look at the original paper this is one of the images they used. The second content image is a portrait of IU – a Korean singer-songwriter and actress. If you're interested... [IU - 삐삐](https://youtu.be/nM0xDI5R50E).\n",
    "\n",
    "### Style Images \n",
    "All of the style images were used in the original NST paper as well. \n",
    "+ _The Shipwreck of the Minotaur_ by JMW Turner (1805)\n",
    "+ _Femme nue assise_ by Pablo Picasso (1910)\n",
    "+ _Composition VII_ by Wassily Kandinsky (1913)\n",
    "+ _The Starry Night_ by Vincent van Gogh (1889)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cnn06.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
