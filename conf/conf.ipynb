{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Deep Learning Models with a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction \n",
    "When training a network, there are usually lots of hyperparameters to choose from: how many layers should I use, what optimizer should I use, do I need reguarization, etc. In the Deep Learning Specialization on Coursera, Andrew Ng shows the following image and emphasizes the importance of speeding up this cycle. \n",
    "\n",
    "![Idea, Code, Experiment Cycle](https://cdn-images-1.medium.com/max/1600/1*5hmtyaU_NV5CXm3zHNyT1Q.png)\n",
    "\n",
    "By choosing Keras as our framework, we've made the time between \"idea\" and \"code\" a lot shorter. But if our models require hours to train, the time between code and experiment will be significant. Especially since it delays the time until we start the cycle all over again. Traning models on a GPU will save significant amounts of time. There are lots of options available â€“ PaperSpace, Amazon AWS, and Google Cloud for example â€“ but today I'm going to recommend something I have rarely seen recommended anywhere else. Best of all, it's completely free: Google Colaboratory. \n",
    "\n",
    "---\n",
    "## Comparing Our Options \n",
    "Before explaining how to set up Google Colaboratory, I'll briefly share some alternatives in case you need to use them in the future. If you just want to get started training your models on GPUs, feel free to skip this section. \n",
    "\n",
    "### Option #1: Amazon AWS\n",
    "Using AWS with EC2 and a Deep Learning AMI is probably the most frequently recommended option. Amazon's 12 month free tier makes this sound appealing as well. Unfortunately, there aren't any GPU compute instances available with free tier. In [this guide](https://aws.amazon.com/getting-started/tutorials/get-started-dlami/), Amazon suggests you can get started for just \\$0.13 per hour. That option also does not have a GPU, so I wouldn't recommend it either. Instead, you should select Launch Instance > EC2 > Search for \"Deep Learning\" > Select \"Deep Learning AMI (Linux)\" > p2.xlarge. This is going to be your cheapest GPU compute option on Amazon, and it costs \\$0.90 per hour ðŸ˜“ I don't recommend it because of the price, plus if you forget to disable your instances you'll end up paying for unused compute time.\n",
    "\n",
    "### Option #2: Google Cloud Platform \n",
    "An alternative to AWS is [Google Cloud Platform](https://cloud.google.com/). If you search \"Google Cloud Free 300\" you'll see that you can get 12 months of free tier access with \\$300 in credits. I personally have not used this option, so seek out tutorials on how to set it up. However, while I have seen posts claiming you can use the \\$300 in credits to pay for credits, [this page](https://cloud.google.com/free/docs/gcp-free-tier) specifically says, \"Your free trial credit applies to all GCP resources, except that you cannot ... add GPUs or TPUs to your instances.\" If you do choose this option, proceed with caution.\n",
    "\n",
    "### Option #3: PaperSpace \n",
    "If you are adamant about spending money to train your models, I recommend using PaperSpace. PaperSpace has a \"Gradient\" version and \"Core\" version. Gradient is the simplest option and provides you with affordable, pre-configured containers. The simplest GPU option is just \\$0.51 per hour and you can train on a Tesla K80 for just \\$0.59 per hour. Again, if you choose this option make sure you terminate your instances when you aren't using them. If you want to be a kind person, consider signing up with my referral link (You'll get \\$10 free credits). Just follow this [link](https://www.paperspace.com/&R=NHJG7FI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Google Colaboratory\n",
    "The simplest and cheapest option is to use [Google Colaboratory](https://colab.research.google.com/). This allows you to access GPUs for free. You can upload Jupyter notebooks from your local machine, from GitHub, or Google Drive. We'll keep our notebooks in Google Drive as it's the simplest option for using custom training sets. Note, however, that Google Drive only provides 15GB storage for free. If you have large datasets, or don't want to download your work to your local machine after training, then you may need to upgrade to the 100GB tier. Fortunately, this only costs \\$2 per month, which is way cheaper than the per hour prices mentioned above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 \n",
    "First, go to your [Google Drive](https://drive.google.com) account. \n",
    "\n",
    "#### Step 2\n",
    "Then, select \"new\" and from the dropdown select \"more\" \n",
    "![Step 2](./images/step01.png)\n",
    "\n",
    "#### Step 3\n",
    "Next, either select \"Colaboratory\" or select \"Connect more apps\" and search for \"Colaboratory\"\n",
    "![Step 3](./images/step02.png)\n",
    "\n",
    "#### Step 4\n",
    "This should create a new folder called \"Colab Notebooks\". Open this.\n",
    "![Step 4](./images/step03.png)\n",
    "\n",
    "#### Step 5\n",
    "From within this folder, select New > More > Colaboratory. This will launch a Jupyter notebook which you can rename whatever you'd like. I renamed it \"test.ipynb\"\n",
    "![Step 5](./images/step04.png)\n",
    "\n",
    "#### Step 6\n",
    "To use a GPU, select Runtime > Runtime Type > and change the hardware accelerator to GPU. \n",
    "![Step 6](./images/step05.png)\n",
    "\n",
    "#### Step 7\n",
    "Then, to connect, select Connect > Connect to a Hosted Runtime \n",
    "![Step 7](./images/step06.png)\n",
    "\n",
    "#### Step 8\n",
    "At this point, you're set up on a GPU and good to go. However, I imagine you want to access some files from your drive account. To do this, you have to 'mount' your drive. To do this, run this code in your notebook and follow the output instructions. \n",
    "```python \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "```\n",
    "This is what you should see when you're done.\n",
    "![Step 8](./images/step07.png)\n",
    "\n",
    "#### Step 9 \n",
    "Now you can use this like any other Jupyter notebook. To access files from your Google Drive, just prepend '/content/drive/' to the filepath. For example, to access files in the same directory use \n",
    "```python \n",
    "base_path = '/content/drive/My Drive/Colab Notebooks/'\n",
    "```\n",
    "\n",
    "#### Step 10 \n",
    "When you are done, select Runtime > Manage Sessions > Terminate. While your GPU time is free, it is a good habit to get into in case you move to paid options. Furthermore, there's no guarantee that Google won't cut you off. \n",
    "![Step 10](./images/step08.png)\n",
    "\n",
    "#### Final Notes\n",
    "If you're training a model for a long time, you're going to want to save it along the way in case Google slows down your access temporarily. Just add calls to `model.save()` at reasonable intervals. Finally, don't use this for cryptocurrency mining, it is against the terms of use. Anyway, that's all you have to do to have a free GPU powered deep learning environment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
